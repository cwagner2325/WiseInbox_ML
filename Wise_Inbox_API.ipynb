{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1KTnxT6vUU93cSIxQ2uTfV7IPC50POcvH",
      "authorship_tag": "ABX9TyOBdjEkIm4binKqMmaNZZF8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cwagner2325/WiseInbox_ML/blob/main/Wise_Inbox_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS9TTfB_nIl0"
      },
      "outputs": [],
      "source": [
        "!pip install fastapi\n",
        "!pip install uvicorn\n",
        "!pip install pickle5\n",
        "!pip install pydantic\n",
        "!pip install scikit-learn\n",
        "!pip install requests\n",
        "!pip install pypi-json\n",
        "!pip install pyngrok\n",
        "!pip install nest-asyncio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import pickle\n",
        "import json\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import nest_asyncio\n",
        "import random\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from pyngrok import conf"
      ],
      "metadata": {
        "id": "OSIh9lLguWZA"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = FastAPI()"
      ],
      "metadata": {
        "id": "3M3gj8Knum4F"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "origins = [\"*\"] # Change this to local host probably\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=origins,\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")"
      ],
      "metadata": {
        "id": "J_ldF_cPupgQ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class model_input(BaseModel):\n",
        "\n",
        "    Email : str\n",
        "    Sender: str\n",
        "    Subject : str"
      ],
      "metadata": {
        "id": "jzTzJRrnurtd"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example I found online. This guy used pickle to export a ML model as a file\n",
        "# And then open the model and store it as a variable again using Pickle\n",
        "\n",
        "# email_model = pickle.load(open('email_model.sav', 'rb'))"
      ],
      "metadata": {
        "id": "HwlxDP2AvOgD"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.post('/email_prediction')\n",
        "def email_prediction(input_parameters : model_input):\n",
        "\n",
        "    print(\"Email Prediction Reached\")\n",
        "    input_data = input_parameters.json()\n",
        "    input_dictionary = json.loads(input_data)\n",
        "\n",
        "    email = input_dictionary['Email']\n",
        "    sender = input_dictionary['Sender']\n",
        "    subject = input_dictionary['Subject']\n",
        "\n",
        "\n",
        "    input_list = [email, sender, subject]\n",
        "\n",
        "    prediction = random.randint(60, 100)\n",
        "    print(prediction)\n",
        "\n",
        "    # prediction = email_model.predict([input_list])\n",
        "\n",
        "\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "xgBICSj-u8xc"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"TOKEN\"] = userdata.get(\"TOKEN\")\n",
        "ngrok.set_auth_token(os.environ[\"TOKEN\"])\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ot0d9HUowPUY",
        "outputId": "672c4e9c-c6ad-44e7-ec44-d5bc6641ce42"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://27d8-35-245-119-48.ngrok-free.app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [249]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n",
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [249]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qk2NHPkUwR5I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}