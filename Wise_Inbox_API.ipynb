{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cwagner2325/WiseInbox_ML/blob/main/Wise_Inbox_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS9TTfB_nIl0"
      },
      "outputs": [],
      "source": [
        "!pip install fastapi\n",
        "!pip install uvicorn\n",
        "!pip install pickle5\n",
        "!pip install pydantic\n",
        "!pip install scikit-learn\n",
        "!pip install requests\n",
        "!pip install pypi-json\n",
        "!pip install pyngrok\n",
        "!pip install nest-asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OSIh9lLguWZA"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import pickle\n",
        "import json\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import nest_asyncio\n",
        "import random\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from pyngrok import conf\n",
        "from time import sleep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3M3gj8Knum4F"
      },
      "outputs": [],
      "source": [
        "app = FastAPI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "J_ldF_cPupgQ"
      },
      "outputs": [],
      "source": [
        "origins = [\"*\"]\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=origins,\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jzTzJRrnurtd"
      },
      "outputs": [],
      "source": [
        "class model_input(BaseModel):\n",
        "\n",
        "    Email : str\n",
        "    Sender: str\n",
        "    Subject : str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HwlxDP2AvOgD"
      },
      "outputs": [],
      "source": [
        "# Example I found online. This guy used pickle to export a ML model as a file\n",
        "# And then open the model and store it as a variable again using Pickle\n",
        "\n",
        "# email_model = pickle.load(open('email_model.sav', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xgBICSj-u8xc"
      },
      "outputs": [],
      "source": [
        "@app.post('/email_prediction')\n",
        "def email_prediction(input_parameters : model_input):\n",
        "    input_data = input_parameters.json()\n",
        "    input_dictionary = json.loads(input_data)\n",
        "\n",
        "    email = input_dictionary['Email']\n",
        "    sender = input_dictionary['Sender']\n",
        "    subject = input_dictionary['Subject']\n",
        "\n",
        "\n",
        "    input_list = [email, sender, subject]\n",
        "\n",
        "    sleep(.5)\n",
        "\n",
        "    prediction = random.randint(40, 100)\n",
        "    print(prediction)\n",
        "\n",
        "    # prediction = email_model.predict([input_list])\n",
        "\n",
        "    return {\"prediction\": prediction}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ot0d9HUowPUY",
        "outputId": "bfd17e40-0882-437d-a1d0-8e2b42052240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://83eb-34-80-54-180.ngrok-free.app\n",
            "Here is a test command to run in a terminal: \n",
            "curl --insecure -X POST -H \"Content-Type: application/json\" -d '{\n",
            "\t\"Email\": \"example@example.com\",\n",
            "\t\"Sender\": \"John Doe\",\n",
            "\t\"Subject\": \"Important News\" \n",
            "}' https://83eb-34-80-54-180.ngrok-free.app/email_prediction\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [177]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43\n",
            "INFO:     64.59.248.215:0 - \"POST /email_prediction HTTP/1.1\" 200 OK\n",
            "52\n",
            "INFO:     64.59.248.215:0 - \"POST /email_prediction HTTP/1.1\" 200 OK\n",
            "63\n",
            "INFO:     64.59.248.215:0 - \"POST /email_prediction HTTP/1.1\" 200 OK\n",
            "79\n",
            "INFO:     64.59.248.215:0 - \"POST /email_prediction HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [177]\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"TOKEN\"] = userdata.get(\"TOKEN\")\n",
        "ngrok.set_auth_token(os.environ[\"TOKEN\"])\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "print(\"Here is a test command to run in a terminal: \")\n",
        "print('curl --insecure -X POST -H \"Content-Type: application/json\" -d \\'{\\n' +\n",
        "      '\\t\"Email\": \"example@example.com\",\\n\\t\"Sender\": \"John Doe\",\\n\\t\"Subject\": \"Important News\" \\n}\\' ' +\n",
        "      ngrok_tunnel.public_url + \"/email_prediction\")\n",
        "\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qk2NHPkUwR5I"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1KTnxT6vUU93cSIxQ2uTfV7IPC50POcvH",
      "authorship_tag": "ABX9TyOfTAXkqkfzOerfX9smonUf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}